CREATE SCHEMA make_it_leak;
SET search_path TO make_it_leak;
CREATE FUNCTION leaky_int8_avg_combine(internal, internal)
    RETURNS internal
AS '@libdir@/regress@DLSUFFIX@', 'leaky_int8_avg_combine'
    LANGUAGE C IMMUTABLE;
CREATE FUNCTION good_int8_avg_combine(internal, internal)
    RETURNS internal
AS '@libdir@/regress@DLSUFFIX@', 'good_int8_avg_combine'
    LANGUAGE C IMMUTABLE;
CREATE AGGREGATE leaky_sum(int8) (
SFUNC = int8_avg_accum,
STYPE = internal,
FINALFUNC = numeric_poly_sum,
COMBINEFUNC = leaky_int8_avg_combine,
SERIALFUNC = int8_avg_serialize,
DESERIALFUNC = int8_avg_deserialize
);
CREATE AGGREGATE good_sum(int8) (
    SFUNC = int8_avg_accum,
    STYPE = internal,
    FINALFUNC = numeric_poly_sum,
    COMBINEFUNC = good_int8_avg_combine,
    SERIALFUNC = int8_avg_serialize,
    DESERIALFUNC = int8_avg_deserialize
    );
CREATE TABLE foo (a int, b int8, c int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
INSERT INTO foo SELECT 0, i, i FROM generate_series(1, 6144) i;
SET statement_mem TO '48MB';
-- need to lower gp_vmem_protect_limit with gpconfig
-- gpconfig -c gp_vmem_protect_limit -v 256
-- gpstop -ar
EXPLAIN (ANALYZE, COSTS OFF) SELECT good_sum(b) FROM foo GROUP BY c;
                                                               QUERY PLAN                                                                
-----------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice2; segments: 3) (actual time=261.490..277.714 rows=6144 loops=1)
   ->  Result (actual time=254.159..268.918 rows=2052 loops=1)
         ->  HashAggregate (actual time=254.155..268.332 rows=2052 loops=1)
               Group Key: c
               Extra Text: (seg0)   2052 groups total in 32 batches; 1 overflows; 2052 spill groups.
 (seg0)   Hash chain length 2.4 avg, 8 max, using 952 of 1088 buckets; total 1 expansions.
 
               ->  Redistribute Motion 3:3  (slice1; segments: 3) (actual time=11.401..14.609 rows=2052 loops=1)
                     Hash Key: c
                     ->  Result (actual time=7.631..20.070 rows=6144 loops=1)
                           ->  HashAggregate (actual time=7.628..18.328 rows=6144 loops=1)
                                 Group Key: c
                                 Extra Text: (seg1)   Hash chain length 3.2 avg, 10 max, using 1948 of 2048 buckets; total 6 expansions.
 
                                 ->  Seq Scan on foo (actual time=0.088..2.083 rows=6144 loops=1)
 Planning time: 34.853 ms
   (slice0)    Executor memory: 183K bytes.
   (slice1)    Executor memory: 363K bytes avg x 3 workers, 908K bytes max (seg1).
 * (slice2)    Executor memory: 37943K bytes avg x 3 workers, 37943K bytes max (seg0).  Work_mem: 24473K bytes max, 2562K bytes wanted.
 Memory used:  49152kB
 Memory wanted:  5622kB
 Optimizer: Pivotal Optimizer (GPORCA) version 3.63.0
 Execution time: 291.544 ms
(23 rows)

EXPLAIN (ANALYZE, COSTS OFF) SELECT leaky_sum(b) FROM foo GROUP BY c;
ERROR:  Canceling query because of high VMEM usage. Used: 231MB, available 25MB, red zone: 230MB (runaway_cleaner.c:189)  (seg0 slice2 10.64.5.219:25432 pid=86756) (runaway_cleaner.c:189)
